
















\chapter{Validation \& Results}


The system used to test these algorithms was an Intel i7-7700k running at 4.5 Ghz, 64GB of DD4 RAM, and a 400GB Intel NVMe SSD hard drive with 2.5GB/s throughput. All algorithms where implemented in generic standard template library C++11. As the nature of this problem relies upon complete enumeration of all transversals regardless of memory usage, compute time alone is used as the metric of performance.  Inefficient memory usage is reflected in longer execution time should the virtual memory system be used.

The following validation procedure was used. The naive algorithm results were collected as control, branch and bound was validated against the naive control, and last the NC-Dynamic solution was validated against naive as well. 

The validation of a single hypergraph in this system consisted of iterating over the intermediate hypergraphs and testing each one. An intermediate hypergraph is constructed by taking the original hypergraph and iterating over one edge, two edges, etc, and constructing a hypergraph from each list of edges. This is an exponential slowdown in validation but also allows the isolation and repetition of core flaws during the development process. Specifically a ``problem'' instance could be identified by hypergraph number and intermediate number.

The iterative techniques to generate all hypergraphs where connected to the validation and testing system to prove correctness.The generative functions for hypergraphs are exponentially-exponential on the order of $N^{{N-1}^{{N-2}^{...}}}$.
Hypergraphs of size 1,2,3,4,5 and 6 were validated. There were over $6*10^9$ hypergraphs of size 6 and took approximately three days on the test machine running as a single threaded process.  Hypergraphs of size 7 - 12 were started and allowed to run which did not terminate before publication and no errors were detected.


\section{Results}
Unexpected results were found when evaluating the algorithms. As noted previously ~\cite{khachiyan2006efficient}, random hypergraphs with the same number of nodes and edges can vary dramatically in run time performance. The performance for similar systems varied from less than a second to hours. This is possibly indicative of how many possible hypergraphs there are. Given that there are ${200}^{{199}^{{...}^{1}}}$ variations on a 200 node hypergraph, it is possible to select $2^{100}$ hypergraphs from this space and still not have any ``similaraities'' between them. The performance of algorithms depend directly upon the structure of the hypergraph. The first indication was the unexpected winner by magnitudes of performance: ``Branch and Bound''. \\
\begin{center}
\includegraphics[scale=.50]{Solvers.png}
\end{center}

In this case, the authors believe that CPU caching with a small code implementation and an efficient list of integers representation simply outperformed for all of these ``random'' cases. After this was discovered, a database of hard hypergraph problems provided by Takeaki Uno was used for the remaining tests \url{http://research.nii.ac.jp/~uno/dualization.html}. The following categories where examined:

\begin{itemize}
    \item Matching graph (M($N$)): a hypergraph with $n$ even nodes forming an induced matching with a low edges $n/2$ count but a high number of $2^{n/2}$ transversals.
    
     \scalebox{.75}{\input{M.pgf}} 
     
    
    \item Dual Matching graph (DM($n$)): a hypergraph that is the dual (solution) of the Matching graph with a high hyperedge $2^{n/2}$ count and a low number of $n/2$ transversals. $DM(n) = dual(M(n))$
    
     \scalebox{.75}{\input{DM.pgf}}
    
    \item Threshold graph (TH($N$)): a hypergraph with $n$ even nodes and hyperedge set $\{\{i,j\}:1 \leq i \le j \leq n, j$ is even$\}$ with a low hyperedges ${n^2}/4$ count and low number of  $n/2 +1$ transversals.
    
     \scalebox{.75}{\input{TH.pgf}}   
    
    \item Self-Dual Threshold graph (SDTH($n$)): a self-dual hypergraph with $n$ nodes obtained from $TH(n)$ and $dual(TH(n))$ as follows: $$SDTH = \{ \{n-1,n\}\} \cup \{ \{n-1\} \cup E | E \in TH(n-2) \} \cup \{\{n\} \cup E|E\in dual(TH(n-2)) \} $$
    
      \scalebox{.75}{\input{SDTH.pgf}} 

    \item Self-Dual Fano-Plane graph (SDFP($n$)): a hypergraph with $n$ nodes and $((k-2)^2/4 + k/2 + 1)$ hyperedges, where $k = (n-2)/7$. To construct it start with the hypergraph $H_0=\{\{1,2,3\},\{1,5,6\},\{1,7,4\},\{2,4,5\},\{2,6,7\},\{3,4,6\},\{3,5,7\}\}$ that represent the set of lines in a Fano-plane and is self-dual. Set $H=H_1 \cup H_2 \cup ... H_k$ where $H_1,H_2,...,H_k$ are $k$ disjoint copies of $H_0$. The dual graph of $H$ is the hypergraph of all $7^k$ unions obtained by taking one hyperedge from each of the $k$ copies of $H_0$. Last, the SDFP hypergraph is a self-dual $H$ as per the SDTH procedure. 
    
     \scalebox{.75}{\input{SDFP.pgf}} 
    
    \item accidents (ac): the complement of the set of maximal frequent item sets with support threshold $t$ of the FIMI accident dataset.
    
     \scalebox{.75}{\input{ac.pgf}} 
    
    \item connect-4 (win): the $t$  minimal winning board positions of the Connect Four game taken from the UCI machine learning repository.
    
     \scalebox{.75}{\input{win.pgf}} 
    
    \item connect-4 (loss): the $t$  minimal losing board positions of the Connect Four game  taken from the UCI machine learning repository.
    
     \scalebox{.75}{\input{lose.pgf}}
    
\end{itemize}

 

 
 
 